# 关于

这是一个系统学习 AI 基础设施 (AI Infra) 的博客，涵盖从底层 GPU 编程到上层推理服务的全栈技术。

## 内容涵盖

- **CUDA 并行编程** — GPU 编程模型、内存优化、高性能计算（参考 PMPP 教材等资料）
- **推理引擎** — vLLM、TensorRT 等主流推理框架的原理与实践
- **模型服务化** — NVIDIA Triton Inference Server 等推理服务部署方案
- **编译器与算子优化** — OpenAI Triton、算子融合、Kernel 自动生成等
- **AI Infra 全链路** — 训练、推理、调度、部署等基础设施架构与最佳实践

后续还会持续扩展更多 AI Infra 相关主题。

## 源码

所有代码示例都在 [src 目录](https://github.com/Blueboylee/PMPP_cpp_AI_infra/tree/main/src) 中。
