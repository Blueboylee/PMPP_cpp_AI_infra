# ğŸš€ æ¨ç†å¼•æ“ä¸æœåŠ¡åŒ–

æ¢ç´¢ vLLMã€NVIDIA Triton Inference Serverã€TensorRT ç­‰æ¨ç†æ¡†æ¶ä¸éƒ¨ç½²æ–¹æ¡ˆã€‚

---

<div class="paper-grid">

<a class="paper-card" href="./vllm-paper">
  <div class="paper-icon">ğŸ“„</div>
  <div class="paper-body">
    <h3>vLLM: Easy, Fast, and Cheap LLM Serving with PagedAttention</h3>
    <p class="paper-meta">Woosuk Kwon et al. Â· UC Berkeley Â· 2023</p>
    <p class="paper-desc">æå‡º PagedAttention æœºåˆ¶ï¼Œé€šè¿‡è™šæ‹Ÿå†…å­˜åˆ†é¡µç®¡ç† KV Cacheï¼Œå¤§å¹…æå‡ LLM æ¨ç†ååé‡ï¼Œå‡å°‘å†…å­˜æµªè´¹ã€‚</p>
    <div class="paper-tags">
      <span class="tag">vLLM</span>
      <span class="tag">PagedAttention</span>
      <span class="tag">KV Cache</span>
      <span class="tag">LLM Serving</span>
    </div>
  </div>
</a>

<a class="paper-card" href="./tensorrt-llm">
  <div class="paper-icon">ğŸ“„</div>
  <div class="paper-body">
    <h3>TensorRT-LLM: A High-Performance Inference Framework for LLMs</h3>
    <p class="paper-meta">NVIDIA Â· 2024</p>
    <p class="paper-desc">NVIDIA æ¨å‡ºçš„é«˜æ€§èƒ½ LLM æ¨ç†æ¡†æ¶ï¼Œæ”¯æŒé‡åŒ–ã€Kernel èåˆã€In-flight Batching ç­‰æ ¸å¿ƒä¼˜åŒ–æŠ€æœ¯ã€‚</p>
    <div class="paper-tags">
      <span class="tag">TensorRT</span>
      <span class="tag">é‡åŒ–</span>
      <span class="tag">Kernel èåˆ</span>
      <span class="tag">NVIDIA</span>
    </div>
  </div>
</a>

<a class="paper-card" href="./triton-inference-server">
  <div class="paper-icon">ğŸ“„</div>
  <div class="paper-body">
    <h3>NVIDIA Triton Inference Server: æ¨¡å‹æœåŠ¡åŒ–éƒ¨ç½²å®è·µ</h3>
    <p class="paper-meta">NVIDIA Â· Triton Inference Server</p>
    <p class="paper-desc">å­¦ä¹  Triton Inference Server çš„æ¶æ„è®¾è®¡ã€æ¨¡å‹ä»“åº“ç®¡ç†ã€åŠ¨æ€æ‰¹å¤„ç†ä¸å¤šæ¨¡å‹ç¼–æ’ç­‰ç”Ÿäº§çº§éƒ¨ç½²æ–¹æ¡ˆã€‚</p>
    <div class="paper-tags">
      <span class="tag">Triton Server</span>
      <span class="tag">Model Serving</span>
      <span class="tag">Dynamic Batching</span>
    </div>
  </div>
</a>

<a class="paper-card" href="./sglang">
  <div class="paper-icon">ğŸ“„</div>
  <div class="paper-body">
    <h3>SGLang: Efficient Execution of Structured Language Model Programs</h3>
    <p class="paper-meta">Lianmin Zheng et al. Â· UC Berkeley & Stanford Â· 2024</p>
    <p class="paper-desc">æå‡ºç»“æ„åŒ–ç”Ÿæˆè¯­è¨€ SGLangï¼Œé€šè¿‡ RadixAttentionï¼ˆKV Cache è‡ªåŠ¨å¤ç”¨ï¼‰ã€å‹ç¼©æœ‰é™çŠ¶æ€æœºï¼ˆé«˜é€Ÿçº¦æŸè§£ç ï¼‰å’Œ API æ¨æµ‹æ‰§è¡Œä¸‰å¤§ä¼˜åŒ–ï¼Œå°†å¤æ‚ LLM ç¨‹åºåŠ é€Ÿæœ€é«˜ 6.4 å€ã€‚</p>
    <div class="paper-tags">
      <span class="tag">SGLang</span>
      <span class="tag">RadixAttention</span>
      <span class="tag">Constrained Decoding</span>
      <span class="tag">LLM Programming</span>
    </div>
  </div>
</a>

</div>

::: tip ğŸ’¡ æŒç»­æ›´æ–°ä¸­
æ›´å¤šæ¨ç†å¼•æ“ä¸æœåŠ¡åŒ–ç›¸å…³çš„è®ºæ–‡è§£è¯»å’Œå­¦ä¹ ç¬”è®°å°†é™†ç»­æ›´æ–°ï¼Œæ•¬è¯·å…³æ³¨ï¼
:::

<style>
.paper-grid {
  display: grid;
  grid-template-columns: 1fr;
  gap: 16px;
  margin: 24px 0;
}

@media (min-width: 768px) {
  .paper-grid {
    grid-template-columns: repeat(2, 1fr);
  }
}

.paper-card {
  display: flex;
  gap: 16px;
  padding: 20px;
  border: 1px solid var(--vp-c-divider);
  border-radius: 12px;
  text-decoration: none !important;
  color: inherit !important;
  transition: all 0.3s ease;
  background: var(--vp-c-bg-soft);
}

.paper-card:hover {
  border-color: var(--vp-c-brand-1);
  box-shadow: 0 4px 16px rgba(0, 0, 0, 0.08);
  transform: translateY(-2px);
}

.paper-icon {
  font-size: 28px;
  flex-shrink: 0;
  margin-top: 2px;
}

.paper-body h3 {
  margin: 0 0 6px 0;
  font-size: 16px;
  font-weight: 600;
  line-height: 1.4;
  color: var(--vp-c-text-1);
}

.paper-meta {
  margin: 0 0 8px 0;
  font-size: 13px;
  color: var(--vp-c-text-3);
}

.paper-desc {
  margin: 0 0 12px 0;
  font-size: 14px;
  color: var(--vp-c-text-2);
  line-height: 1.6;
}

.paper-tags {
  display: flex;
  flex-wrap: wrap;
  gap: 6px;
}

.tag {
  padding: 2px 10px;
  font-size: 12px;
  border-radius: 999px;
  background: var(--vp-c-brand-soft);
  color: var(--vp-c-brand-1);
  font-weight: 500;
}
</style>
