---
title: "PMPP Ch07: Convolution"
date: 2026-02-19
---

# Ch07: Convolution

<p style="color: var(--vp-c-text-2); font-size: 14px;">
2026-02-19 &nbsp;·&nbsp; PMPP 专栏 &nbsp;·&nbsp; 第七章
</p>

> **本章信息**
> - **书名**: Programming Massively Parallel Processors: A Hands-on Approach (4th Edition)
> - **作者**: David B. Kirk, Wen-mei W. Hwu
> - **范围**: 第 7 章 Convolution
> - **配套代码**: [ch07_convolution.cu](https://github.com/Blueboylee/AI-INFRA-ALL-IN-ONE/blob/main/src/pmpp/cuda/ch07_convolution.cu)

## 一句话总结

本章将前几章学到的优化技术系统应用到 **卷积** 这一经典算子上：从 1D/2D 卷积的数学定义与串行算法出发，逐步引入 **常量内存**（卷积核广播）、**Tiled 卷积** 与 **Halo 元素** 处理，把卷积从“每输出点重复读入整块邻域”的朴素实现，优化为“按块加载、复用、减少全局内存访问”的高效实现，为理解 cuDNN 等库中的卷积优化打下基础。

---

## 7.1 卷积定义与串行算法

### 1D 卷积

一维离散卷积（本节默认“有效”或“同尺寸”输出，边界外视为 0）定义为：

$$
y[i] = (x * m)[i] = \sum_{j=0}^{M-1} x[i+j] \cdot m[j]
$$

其中：
- \(x\)：长度为 \(N\) 的输入信号
- \(m\)：长度为 \(M\) 的卷积核（mask / kernel）
- \(y\)：输出，长度 \(N\)（若越界处 \(x[\cdot]=0\)）

```
1D 卷积示意 (N=8, M=3):

输入 x:  [x0 x1 x2 x3 x4 x5 x6 x7]
卷积核 m: [m0 m1 m2]

y[0] = x[0]*m0 + x[1]*m1 + x[2]*m2
y[1] = x[1]*m0 + x[2]*m1 + x[3]*m2
y[2] = x[2]*m0 + x[3]*m1 + x[4]*m2
...
y[7] = x[7]*m0 + 0*m1 + 0*m2   (越界补 0)
```

串行实现：对每个输出下标 \(i\)，内层循环 \(j=0..M-1\) 累加 \(x[i+j]\cdot m[j]\)。时间复杂度 \(O(N \cdot M)\)。

### 2D 卷积

二维离散卷积（图像与 2D 卷积核）：

$$
y[r][c] = \sum_{d_r=0}^{M_r-1} \sum_{d_c=0}^{M_c-1} x[r+d_r][c+d_c] \cdot m[d_r][d_c]
$$

边界外同样视为 0。串行实现为四重循环，复杂度 \(O(N_r \cdot N_c \cdot M_r \cdot M_c)\)。

```
2D 卷积 (3x3 卷积核):

输入 tile:        卷积核:
a b c             m00 m01 m02
d e f      *      m10 m11 m12
g h i             m20 m21 m22

输出一点 = a*m00 + b*m01 + c*m02 + d*m10 + e*m11 + f*m12 + g*m20 + h*m21 + i*m22
```

### 卷积的访存与计算强度

以 1D 为例，每个输出点要读 \(M\) 个输入和 \(M\) 个权值（权值可复用），写 1 个输出。若权值放在常量/只读缓存中，主要流量是输入与输出：

- 每输出点：读 \(M\) 个 float，写 1 个 float；FLOPs 约 \(2M\)（乘加）。
- 算术强度（按输入+输出字节计）约 \(\frac{2M}{4(M+1)} \approx 0.5\)（M 较小时），属于 **内存受限**。因此优化重点在于：**减少对输入的重复读取**（Tiling + Halo）和 **高效提供权值**（常量内存）。

---

## 7.2 1D 卷积的并行化：基础 Kernel

### 并行策略

输出点之间无数据依赖，可按输出下标并行：每个线程负责一个（或若干）\(i\)，计算 \(y[i]\)。

```
1D 卷积并行划分:

Thread 0  → y[0]   = sum_j x[0+j]*m[j]
Thread 1  → y[1]   = sum_j x[1+j]*m[j]
...
Thread i  → y[i]   = sum_j x[i+j]*m[j]
```

### 基础 CUDA Kernel（卷积核在全局内存）

```c
__global__ void conv1d_basic(const float* in, float* out, const float* mask,
                             int n, int maskLen) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i >= n) return;

    float sum = 0.0f;
    for (int j = 0; j < maskLen; j++) {
        int idx = i + j;
        float val = (idx < n) ? in[idx] : 0.0f;
        sum += val * mask[j];
    }
    out[i] = sum;
}
```

特点：
- 每个线程独立从全局内存读 `in[i..i+maskLen-1]` 和 `mask[0..maskLen-1]`。
- 输入访问连续（stride=1），可合并；但同一 warp 内对 `mask[j]` 的访问一致，若 mask 在全局内存会重复读同一地址，浪费带宽。
- 边界用 clamp：越界下标取 0。

---

## 7.3 常量内存优化：卷积核

### 为什么用常量内存

卷积核 \(m\) 在全体线程间 **共享且只读**，且尺寸通常很小（如 1D 的 \(M \le 32\)，2D 的 3×3、5×5）。适合放入 **常量内存（Constant Memory）**：

- 有专用 cache，多线程读同一地址时只发生一次内存访问，其余命中 cache（广播）。
- 容量较小（通常 64 KB），适合小卷积核。

```
常量内存 vs 全局内存 (同一 Warp 读 mask[j]):

全局内存: 32 个线程各发 1 次 load(mask+j) → 若未合并则 32 次事务
常量内存: 32 个线程读同一地址 → 1 次广播，其余命中 constant cache
```

### 使用方式

1. 在设备端用 `__constant__` 声明（大小编译期固定，如 `MAX_MASK_1D`）。
2. 在 Host 用 `cudaMemcpyToSymbol(c_mask_1d, h_mask, maskLen * sizeof(float))` 上传。
3. Kernel 内直接读 `c_mask_1d[j]`，不再通过参数传指针。

```c
__constant__ float c_mask_1d[MAX_MASK_1D];

__global__ void conv1d_constant(const float* in, float* out,
                                 int n, int maskLen) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i >= n) return;

    float sum = 0.0f;
    for (int j = 0; j < maskLen; j++) {
        int idx = i + j;
        float val = (idx < n) ? in[idx] : 0.0f;
        sum += val * c_mask_1d[j];  // 从常量内存读
    }
    out[i] = sum;
}
```

配套代码中 1D/2D 均提供“全局 mask”与“常量 mask”两版，可对比带宽与耗时。

---

## 7.4 Tiled 卷积与 Halo 元素

### 动机：重复读取

在基础 Kernel 中，相邻输出点共享大量输入：计算 \(y[i]\) 和 \(y[i+1]\) 都会用到 \(x[i+1],\ldots,x[i+M-1]\)。若每个线程独立从全局内存读，同一输入会被多次加载。Tiling 思路：**按块（Tile）把输入加载到 Shared Memory，块内输出从 Shared Memory 读**，从而复用数据、减少全局内存访问。

### Halo（光晕）区域

一个输出块对应输入上的一段连续区间。输出块覆盖下标 \([B, B+T)\) 时，计算这些输出需要输入下标 \([B, B+T+M-1]\)（因为最大偏移是 \(i+M-1\)，\(i\) 最大为 \(B+T-1\)）。因此：

- “核内”输入长度 = \(T\)（与输出块一致）
- 右侧多出的 \(M-1\) 个元素称为 **Halo**（光晕）

```
1D Tiled 卷积 (TILE=8, M=3):

输出块:  y[0]..y[7]  需要输入  x[0]..x[9]
         |<- TILE ->|  Halo ->|M-1=2|

         [  Tile  (8)  ][ Halo (2) ]
输入:     x0 x1 ... x7 | x8 x9
                       ^^^^^ 仅最右 2 个为 Halo
```

定义：
- `TILE_1D`：每块输出点数
- `HALO_1D = maskLen - 1`：块右侧 Halo 长度
- Shared Memory 大小：`TILE_1D + HALO_1D`（即每块要加载的连续输入长度）

### 1D Tiled Kernel 步骤

1. **协作加载**：Block 内线程一起把本块需要的 `in[base..base+TILE_1D+HALO_1D-1]` 装入 `__shared__ float tile[]`，边界外填 0。
2. **同步**：`__syncthreads()`。
3. **计算**：每个线程用 `tile[tx + j]` 和 `c_mask_1d[j]` 计算一个输出点，不再访问全局 `in`。

```c
__shared__ float tile[TILE_1D + HALO_1D];

int base = blockIdx.x * TILE_1D;
int tx = threadIdx.x;

// 加载：主块 + 右侧 Halo 由边界线程加载
tile[tx] = (base + tx < n) ? in[base + tx] : 0.0f;
if (tx < HALO_1D)
    tile[TILE_1D + tx] = (base + TILE_1D + tx < n) ? in[base + TILE_1D + tx] : 0.0f;
__syncthreads();

int i = base + tx;
if (i >= n) return;
float sum = 0.0f;
for (int j = 0; j < maskLen; j++)
    sum += tile[tx + j] * c_mask_1d[j];
out[i] = sum;
```

### 访存对比（1D）

| 版本 | 每输出点读入（全局） | 每输出点读 mask |
|------|----------------------|-----------------|
| Basic | \(M\) 次（可能重复） | 全局 \(M\) 次 |
| Constant | \(M\) 次 | 常量 cache 广播 |
| Tiled | 约 \(1\) 次（摊到 tile 内复用） | 常量 cache |

Tiled 把“每点读 \(M\) 次全局输入”降为“每点约 1 次”（按块摊），显著降低全局带宽压力。

---

## 7.5 2D 卷积的推广

### 2D 基础 Kernel

每个线程对应一个输出像素 \((r,c)\)，二重循环遍历卷积核 \((d_r, d_c)\)，从 `in[(r+dr)*cols+(c+dc)]` 和 `mask[dr*maskCols+dc]` 做乘加。边界判断：若 `r+dr`、`c+dc` 越界则输入取 0。

```c
int r = blockIdx.y * blockDim.y + threadIdx.y;
int c = blockIdx.x * blockDim.x + threadIdx.x;
if (r >= rows || c >= cols) return;
float sum = 0.0f;
for (int dr = 0; dr < maskRows; dr++)
    for (int dc = 0; dc < maskCols; dc++) {
        int ir = r + dr, ic = c + dc;
        float val = (ir >= 0 && ir < rows && ic >= 0 && ic < cols)
                    ? in[ir * cols + ic] : 0.0f;
        sum += val * c_mask_2d[dr * maskCols + dc];
    }
out[r * cols + c] = sum;
```

2D 卷积核同样用 `__constant__` 声明，Host 用 `cudaMemcpyToSymbol` 上传。

### 2D Tiled 与 Halo

对 2D，每个输出块为 \(T\times T\)（如 16×16），卷积核 \(M_r\times M_c\)（如 3×3）。计算一块输出需要输入的矩形区域为：

- 行：\([r_0, r_0+T+M_r-1)\)，即上下各多 \(M_r-1\)（上下 Halo）
- 列：\([c_0, c_0+T+M_c-1)\)，即左右各多 \(M_c-1\)（左右 Halo）

因此 Shared Memory 为 \((T + 2(M_r-1)) \times (T + 2(M_c-1))\)；对 3×3 核，即 \((T+2)\times (T+2)\)（四周各 1 圈 Halo）。

```
2D Tile (T=16, 3x3 mask): 需要 18x18 输入

         halo left (1)   tile (16)   halo right (1)
halo top     [ 1 x 16  ]
(1 row)      [ 16 x 16 ]  <- 输出块对应
halo bottom  [ 1 x 16  ]
```

实现要点：
- Block 维度取 \((T+2, T+2)\)（如 18×18），使每个线程正好加载 Shared 中的一个元素（含 Halo）。
- 全局坐标到 Shared 的映射：`gr = blockIdx.y*T + ty - 1`，`gc = blockIdx.x*T + tx - 1`，越界填 0。
- 只有“内部”线程（如 \(1\le ty,tx \le 16\)）写输出，且用 `tile[ty-1+dr][tx-1+dc]` 与 `c_mask_2d` 做乘加。

配套代码中 2D tiled 使用 `TILE_2D_PAD_R/C` 与 `HALO_2D_R/C`，对 3×3 核为 18×18 的 shared tile，block 为 (18,18)。

---

## 7.6 边界处理

常见策略：

| 策略 | 含义 | 实现 |
|------|------|------|
| Clamp to zero | 越界当 0 | `idx < n ? in[idx] : 0.f` |
| Clamp to edge | 越界取边界值 | `in[min(max(idx,0), n-1)]` |
| Replicate / Reflect | 镜像或复制边界 | 按需索引变换 |
| Padding | 事先在输入四周补 0 | 扩大数组，Kernel 内不越界 |

本章实现采用 **clamp to zero**：简单且与很多信号处理约定一致。若需要“同尺寸”输出且边缘不丢信息，可在预处理做 padding，或 Kernel 内按边界规则取输入。

---

## 7.7 与 cuDNN / 深度学习卷积的关系

- **数学形式**：深度学习中的 2D/3D 卷积与本节 2D 卷积一致，多出多通道（多 filter、batch），即 NCHW/NHWC 上的 4D 张量运算。
- **优化层次**：cuDNN 会结合 Winograd、FFT、Implicit GEMM、Direct 等多种算法，并针对不同尺寸、stride、padding 选不同 kernel；本节 Tiled + 常量内存 + Halo 对应其中 **Direct** 类实现的优化思路。
- **扩展**：实际库还会做多通道累加、融合激活、分组卷积、stride>1 等，但“单通道、stride=1、小卷积核”的 Tiled + Halo + 常量内存仍是基础构件。

---

## 7.8 性能对比与带宽估算

以 1D 为例，设 \(N=2^{24}\)，\(M=7\)，每次迭代读入 \(N\) 个 float、写 \(N\) 个 float；若使用常量内存，卷积核读可忽略。

- **Basic**：每线程读 \(M\) 次 `in`、\(M\) 次 `mask`（全局）。有效带宽约 \(N \cdot (M+1) \cdot 4 \text{ B}\) 读 + \(N \cdot 4 \text{ B}\) 写（若 mask 未合并则更差）。
- **Constant**：读入量同上，但 mask 走常量 cache，减少全局压力。
- **Tiled**：每块读 \(T+M-1\) 个 float 到 Shared，写 \(T\) 个 float；摊到每输出点约 1 次全局读 + 1 次全局写，总约 \(2N \cdot 4 \text{ B}\)。

配套代码中通过 `./ch07_convolution 1d` / `./ch07_convolution 2d` 可对比三者的运行时间；通常 Tiled 优于 Constant，Constant 优于 Basic，具体倍数与 \(M\)、\(N\) 及 GPU 型号有关。

---

## 7.9 本章小结

- **1D/2D 卷积**：按输出并行；每点 \(O(M)\) 或 \(O(M_r M_c)\) 次乘加，访存多，属内存受限。
- **常量内存**：小卷积核用 `__constant__` + `cudaMemcpyToSymbol`，实现权值广播与 cache，减少重复读。
- **Tiled + Halo**：按块把输入加载到 Shared Memory，块内复用，显著减少全局内存访问；1D 的 Halo 为块右侧 \(M-1\)，2D 为四周各 \(M_r-1\)/\(M_c-1\)。
- **边界**：示例采用越界为 0；实际可按需做 padding 或 clamp to edge。

配套代码 [ch07_convolution.cu](https://github.com/Blueboylee/AI-INFRA-ALL-IN-ONE/blob/main/src/pmpp/cuda/ch07_convolution.cu) 提供 1D/2D 的 Basic、Constant、Tiled 版本及简单计时，可直接编译运行对比。

---

::: tip 下一章预告
[Ch08: Stencil](./ch08) 将 Stencil 作为一类更通用的邻域计算模式讨论，包括 3D Stencil、寄存器级 Tiling、线程粗化（Thread Coarsening）等，与本章卷积在“邻域 + Tiling”思路上一致，但负载与访存模式不同。
:::

---

## 扩展思考

::: details 思考题 1：1D 卷积的 Tiled 版本中，若 TILE 很小、M 很大，Halo 占比会很大，如何权衡？
TILE 小则每块计算量小、同步与加载次数相对多；M 大则 Halo 长，每块要加载的输入多，Shared Memory 占用大。通常取 TILE 为 256 左右、M 在 32 以内，使 Halo 在 1 个 warp 内能协作加载完，且单块 Shared 不会过大影响 Occupancy。可针对具体 M 和 GPU 的 shared 上限做实验。
:::

::: details 思考题 2：2D 卷积核 5×5 时，Tiled 的 Shared 尺寸应为多少？Block 维度如何选？
需要输入块 \((T+4)\times (T+4)\)（上下左右各 2）。若 \(T=16\)，则为 20×20=400 元素。Block 可设为 (20,20) 共 400 线程，每线程加载 1 个；或 (16,16) 每线程加载约 2 个。需注意 20×20 可能带来 bank conflict，可适当 padding（如 20×21）以对齐。
:::

::: details 思考题 3：常量内存容量有限（如 64KB），若卷积核很大怎么办？
大卷积核（或大量 filter 元）无法全部放进常量内存时，可：只把当前 block 用到的部分放入常量内存并分阶段更新；或使用只读纹理/全局内存 + L2 缓存；或改用 GEMM 形式的卷积（im2col + 矩阵乘），把权值放在全局内存中做 Tiled 矩阵乘。
:::

::: details 思考题 4：卷积与矩阵乘法的关系？
一维卷积可写成“带状”矩阵乘；二维卷积常通过 im2col 展开成一次大矩阵乘法，从而复用成熟的 GEMM 与 Tiled 矩阵乘优化。cuDNN 中很多卷积路径最终调用 GEMM。
:::

::: details 思考题 5：2D Tiled 卷积中 Shared Memory 是否会有 Bank Conflict？
会。若 tile 二维为 \(18\times 18\)，按行存则同一行相邻元素间隔 4 字节，同一 warp 内线程若按列访问（如 `tile[ty+dr][tx+dc]` 中固定 `ty+dr`、变 `dc`），可能产生 32-way 冲突。可对行做 padding（如 18×18 改为 18×20），使同一行内连续 32 个元素落在不同 bank，或调整访问顺序以降低冲突。
:::
